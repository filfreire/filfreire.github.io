---
layout: post
title: "(DRAFT) Jurassic Inatentional blindness"
meta_description: "Jurassic Inatentional blindness"
date: 2019-03-06
categories: [draft]
image: /assets/images/jp_404.jpg
caption: "Replace this, 2018"
---

jurassic park failure- predicted by ian malcolm due - they were not paying attention and purposely blind

state of the world: if a simple chaotician can point to blindness in a fictional and complex system, more complex than most software we use, and if we can use tools fo  purposes other than original, how much more do testers play a part being on guard for this stuff - for stuff that tools and automated checks will most probably fail to scratch

to make matters worse, now we can leverage the power of “testing” libraries to manipulate democratic processes, that supposedly might have been “tested” with resource to automated checks in the first place.
a practical example: rigging the vote for the most influential tester of agileTD 2019.

I do not know who developed or tested their page/form, but, if there was an intention of covering with a predetermined set of automated check tools the “necessary testing efforts” of for example AgileTD vote, then i believe we have one of the causes for the flaw that allows fake votes in agileTD poll. or maybe the inatentional blindness of who oversaw it’s development allied with a not meaningful and not good testing strategy let to a vulnerability in an otherwise aperently democratic process. again, i’m trying to underline the inportance of testers who play a part being on guard for this stuff - for stuff that tools and automated checks will most probably fail to scratch

the technical part of how to exploit agileTD initial democratic vote will be studied in a later blog post.

food for tought: if there’s something i recall from infosec classes at school it is the premiss that the attacker of a given system is always smarter than the defenses we might construct. so I only wonder, we’ve been pointed out that there are  people out there which are leveraging the power of data tools (diff that “testing” tools) to go the extra mile and manipulate elections of countries. so I’m left wondering: are testers in these big (anti)social platforms aware of their responsibility as testers towards their users?

testers have a part in actively detecting blindness that can cause dangers to the users, be those being killed by a dinosaur or being manipulated in an aparent democratic process.